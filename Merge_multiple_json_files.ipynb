{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify input json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_dir` is the path to the directory containing all the json files we need to combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Data/'\n",
    "output_dir = 'Annotations/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch all json file names from `data_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFiles = []\n",
    "filetypes = data_dir + '*.json'\n",
    "for file in glob.glob(filetypes):\n",
    "    jsonFiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/471_to_480.json',\n",
       " 'Data/421_to_430.json',\n",
       " 'Data/441_to_450.json',\n",
       " 'Data/400_to_420.json',\n",
       " 'Data/491_to_500.json',\n",
       " 'Data/431_to_440.json',\n",
       " 'Data/merged_2020_05_27_001-100.json',\n",
       " 'Data/451_to_460.json',\n",
       " 'Data/481_to_490.json',\n",
       " 'Data/461_to_470.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/471_to_480.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/421_to_430.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/441_to_450.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/400_to_420.json, number of keys = 21'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/491_to_500.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/431_to_440.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/merged_2020_05_27_001-100.json, number of keys = 100'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/451_to_460.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/481_to_490.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data/461_to_470.json, number of keys = 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'--------------------------------------------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'MERGED dictionary, number of keys = 201'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_merged = dict()\n",
    "for jf in jsonFiles:\n",
    "    with open(jf) as ojf:\n",
    "        d = json.load(ojf)\n",
    "        display(f'{jf}, number of keys = {len(d.keys())}')\n",
    "        data_merged.update(d)\n",
    "\n",
    "display('--------------------------------------------')\n",
    "display(f'MERGED dictionary, number of keys = {len(data_merged.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lake_471.jpg', 'lake_472.jpg', 'lake_473.jpg', 'lake_474.jpg', 'lake_475.jpg', 'lake_476.jpg', 'lake_477.jpg', 'lake_478.jpg', 'lake_479.jpg', 'lake_480.jpg', 'lake_421.jpg', 'lake_422.jpg', 'lake_423.jpg', 'lake_424.jpg', 'lake_425.jpg', 'lake_426.jpg', 'lake_427.jpg', 'lake_428.jpg', 'lake_429.jpg', 'lake_430.jpg', 'lake_441.jpg', 'lake_442.jpg', 'lake_443.jpg', 'lake_444.jpg', 'lake_445.jpg', 'lake_446.jpg', 'lake_447.jpg', 'lake_448.jpg', 'lake_449.jpg', 'lake_450.jpg', 'lake_400.jpg', 'lake_401.jpg', 'lake_402.jpg', 'lake_403.jpg', 'lake_404.jpg', 'lake_405.jpg', 'lake_406.jpg', 'lake_407.jpg', 'lake_408.jpg', 'lake_409.jpg', 'lake_410.jpg', 'lake_411.jpg', 'lake_412.jpg', 'lake_413.jpg', 'lake_414.jpg', 'lake_415.jpg', 'lake_416.jpg', 'lake_417.jpg', 'lake_418.jpg', 'lake_419.jpg', 'lake_420.jpg', 'lake_491.jpg', 'lake_492.jpg', 'lake_493.jpg', 'lake_494.jpg', 'lake_495.jpg', 'lake_496.jpg', 'lake_497.jpg', 'lake_498.jpg', 'lake_499.jpg', 'lake_500.jpg', 'lake_431.jpg', 'lake_432.jpg', 'lake_433.jpg', 'lake_434.jpg', 'lake_435.jpg', 'lake_436.jpg', 'lake_437.jpg', 'lake_438.jpg', 'lake_439.jpg', 'lake_440.jpg', 'lake_001.jpg', 'lake_002.jpg', 'lake_003.jpg', 'lake_004.jpg', 'lake_005.jpg', 'lake_006.jpg', 'lake_007.jpg', 'lake_008.jpg', 'lake_009.jpg', 'lake_010.jpg', 'lake_011.jpg', 'lake_012.jpg', 'lake_013.jpg', 'lake_014.jpg', 'lake_015.jpg', 'lake_016.jpg', 'lake_017.jpg', 'lake_018.jpg', 'lake_019.jpg', 'lake_020.jpg', 'lake_021.jpg', 'lake_022.jpg', 'lake_023.jpg', 'lake_024.jpg', 'lake_025.jpg', 'lake_026.jpg', 'lake_027.jpg', 'lake_028.jpg', 'lake_029.jpg', 'lake_030.jpg', 'lake_031.jpg', 'lake_032.jpg', 'lake_033.jpg', 'lake_034.jpg', 'lake_035.jpg', 'lake_036.jpg', 'lake_037.jpg', 'lake_038.jpg', 'lake_039.jpg', 'lake_040.jpg', 'lake_041.jpg', 'lake_042.jpg', 'lake_043.jpg', 'lake_044.jpg', 'lake_045.jpg', 'lake_046.jpg', 'lake_047.jpg', 'lake_048.jpg', 'lake_049.jpg', 'lake_050.jpg', 'lake_051.jpg', 'lake_052.jpg', 'lake_053.jpg', 'lake_054.jpg', 'lake_055.jpg', 'lake_056.jpg', 'lake_057.jpg', 'lake_058.jpg', 'lake_059.jpg', 'lake_060.jpg', 'lake_061.jpg', 'lake_062.jpg', 'lake_063.jpg', 'lake_064.jpg', 'lake_065.jpg', 'lake_066.jpg', 'lake_067.jpg', 'lake_068.jpg', 'lake_069.jpg', 'lake_070.jpg', 'lake_071.jpg', 'lake_072.jpg', 'lake_073.jpg', 'lake_074.jpg', 'lake_075.jpg', 'lake_076.jpg', 'lake_077.jpg', 'lake_078.jpg', 'lake_079.jpg', 'lake_080.jpg', 'lake_081.jpg', 'lake_082.jpg', 'lake_083.jpg', 'lake_084.jpg', 'lake_085.jpg', 'lake_086.jpg', 'lake_087.jpg', 'lake_088.jpg', 'lake_089.jpg', 'lake_090.jpg', 'lake_091.jpg', 'lake_092.jpg', 'lake_093.jpg', 'lake_094.jpg', 'lake_095.jpg', 'lake_096.jpg', 'lake_097.jpg', 'lake_098.jpg', 'lake_099.jpg', 'lake_100.jpg', 'lake_451.jpg', 'lake_452.jpg', 'lake_453.jpg', 'lake_454.jpg', 'lake_455.jpg', 'lake_456.jpg', 'lake_457.jpg', 'lake_458.jpg', 'lake_459.jpg', 'lake_460.jpg', 'lake_481.jpg', 'lake_482.jpg', 'lake_483.jpg', 'lake_484.jpg', 'lake_485.jpg', 'lake_486.jpg', 'lake_487.jpg', 'lake_488.jpg', 'lake_489.jpg', 'lake_490.jpg', 'lake_461.jpg', 'lake_462.jpg', 'lake_463.jpg', 'lake_464.jpg', 'lake_465.jpg', 'lake_466.jpg', 'lake_467.jpg', 'lake_468.jpg', 'lake_469.jpg', 'lake_470.jpg'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create label for merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_timestamped_label(st, prefix = '', postfix = '', sep = '_'):\n",
    "    \"\"\" Concatenate prefix, struct_time , and postfix string using the provided seperator.\n",
    "    \"\"\"\n",
    "    candidate_str = []\n",
    "    if prefix:\n",
    "        candidate_str.append(prefix)\n",
    "        \n",
    "    time_str = time.strftime(f'%Y{sep}%m{sep}%d', st)\n",
    "    candidate_str.append(time_str)\n",
    "    \n",
    "    if postfix:\n",
    "        candidate_str.append(postfix)\n",
    "    \n",
    "    full_label = sep.join(candidate_str)\n",
    "    \n",
    "    return full_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the final dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_data = output_dir + construct_timestamped_label(time.gmtime(), prefix = 'merged') + '.json'\n",
    "filename_used_files = output_dir + construct_timestamped_label(time.gmtime(), prefix = 'original_filenames',\n",
    "                                                             postfix = 'merged') + '.txt'\n",
    "\n",
    "with open(filename_data, 'w') as wfile:\n",
    "    json.dump(data_merged, wfile)\n",
    "\n",
    "with open(filename_used_files, 'w') as wfile:\n",
    "    for file in jsonFiles:\n",
    "        wfile.write(f'{file}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
